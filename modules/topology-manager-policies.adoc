// Module included in the following assemblies:
//
// * scaling_and_performance/using-topology-manager.adoc

[id="topology_manager_policies{context}"]
= Topology Manager Policies

Topology Manager works on Nodes:

* with CPU Manager Policy configured as `static`.
* with Pods in the `Guaranteed` QoS class.

When the above conditions are met, Topology Manager will align CPU
and device requests for the Pod.

Topology Manager supports 4 allocation policies. These policies are set via a Kubelet
flag, `--topology-manager-policy.` The policies are:

* `none` (default)
* `best-effort`
* `restricted`
* `single-numa-node`

== none policy

This is the default policy and does not perform any topology alignment

== best-effort policy

For each container in a Guaranteed Pod, kubelet, with best-effort topology
management policy, calls each Hint Provider to discover their resource
availability. Using this information, the Topology Manager stores the
preferred NUMA Node affinity for that container. If the affinity is not
preferred, Topology Manager will store this and admit the pod to the node anyway.

== restricted policy

For each container in a Guaranteed Pod, kubelet, with restricted topology
management policy, calls each Hint Provider to discover their resource
availability. Using this information, the Topology Manager stores the
preferred NUMA Node affinity for that container. If the affinity is not
preferred, Topology Manager will reject this pod from the node. This will
result in a pod in a Terminated state with a pod admission failure

== single-numa-node

For each container in a Guaranteed Pod, kubelet, with single-numa-node topology
management policy, calls each Hint Provider to discover their resource availability.
Using this information, the Topology Manager determines if a single NUMA Node
affinity is possible. If it is, the pod will be admitted to the node.
If, however, this is not possible then the Topology Manager will reject the pod
from the node. This will result in a pod in a Terminated state with a pod admission
failure.


= Pod Interactions with Topology Manager Policies

Consider the containers in the following pod specs:

----
spec:
  containers:
  - name: nginx
    image: nginx
----

This pod runs in the `BestEffort` QoS class because no resource requests or
limits are specified.

----
spec:
  containers:
  - name: nginx
    image: nginx
    resources:
      limits:
        memory: "200Mi"
      requests:
        memory: "100Mi"
----

This pod runs in the `Burstable` QoS class because requests are less than limits.

If the selected policy is anything other than `none`, Topology Manager would
not consider either of these Pod specifications.

----
spec:
  containers:
  - name: nginx
    image: nginx
    resources:
      limits:
        memory: "200Mi"
        cpu: "2"
        example.com/device: "1"
      requests:
        memory: "200Mi"
        cpu: "2"
        example.com/device: "1"
----

This pod runs in the Guaranteed QoS class because requests are equal to limits.

Topology Manager would consider this Pod. The Topology Manager consults the
CPU Manager static policy, which returns the topology of available CPUs. Topology
Manager also consults Device Manager to discover the topology of available devices
for example.com/device.

Topology Manager will use this information to store the best Topology for this
container. In the case of this Pod, CPU and Device Manager will use this stored
information at the resource allocation stage.






